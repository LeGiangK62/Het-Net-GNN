{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb815f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T00:47:51.722207700Z",
     "start_time": "2023-07-05T00:47:44.119633900Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance_matrix\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU, Sigmoid, BatchNorm1d as BN\n",
    "\n",
    "\n",
    "from reImplement import GCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24e591f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T13:45:54.331717Z",
     "start_time": "2023-07-03T13:45:54.323716800Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_channels_wsn(num_ap, num_user, num_samples, var_noise=1.0, radius=1):\n",
    "    # print(\"Generating Data for training and testing\")\n",
    "\n",
    "    # if num_ap != 1:\n",
    "    #     raise Exception(\"Can not generate data for training and testing with more than 1 base station\")\n",
    "    # generate position\n",
    "    dist_mat = []\n",
    "    position = []\n",
    "    index_user = np.tile(np.arange(num_user), (num_ap, 1))\n",
    "    index_ap = np.tile(np.arange(num_ap).reshape(-1, 1), (1, num_user))\n",
    "\n",
    "    index = np.array([index_user, index_ap])\n",
    "\n",
    "    # Calculate channel\n",
    "    CH = 1 / np.sqrt(2) * (np.random.randn(num_samples, 1, num_user)\n",
    "                           + 1j * np.random.randn(num_samples, 1, num_user))\n",
    "\n",
    "    if radius == 0:\n",
    "        Hs = abs(CH)\n",
    "    else:\n",
    "        for each_sample in range(num_samples):\n",
    "            pos = []\n",
    "            pos_BS = []\n",
    "\n",
    "            for i in range(num_ap):\n",
    "                r = radius * (np.random.rand())\n",
    "                theta = np.random.rand() * 2 * np.pi\n",
    "                pos_BS.append([r * np.sin(theta), r * np.cos(theta)])\n",
    "                pos.append([r * np.sin(theta), r * np.cos(theta)])\n",
    "            pos_user = []\n",
    "\n",
    "            for i in range(num_user):\n",
    "                r = 0.5 * radius + 0.5 * radius * np.random.rand()\n",
    "                theta = np.random.rand() * 2 * np.pi\n",
    "                pos_user.append([r * np.sin(theta), r * np.cos(theta)])\n",
    "                pos.append([r * np.sin(theta), r * np.cos(theta)])\n",
    "\n",
    "            pos = np.array(pos)\n",
    "            pos_BS = np.array(pos_BS)\n",
    "            dist_matrix = distance_matrix(pos_BS, pos_user)\n",
    "            # dist_matrixp = distance_matrix(pos[1:], pos[1:])\n",
    "            dist_mat.append(dist_matrix)\n",
    "            position.append(pos)\n",
    "\n",
    "        dist_mat = np.array(dist_mat)\n",
    "        position = np.array(position)\n",
    "\n",
    "        # Calculate Free space pathloss\n",
    "        # f = 2e9\n",
    "        # c = 3e8\n",
    "        # FSPL_old = 1 / ((4 * np.pi * f * dist_mat / c) ** 2)\n",
    "        FSPL = - (120.9 + 37.6 * np.log10(dist_mat/1000))\n",
    "        FSPL = 10 ** (FSPL / 10)\n",
    "\n",
    "        # print(f'FSPL_old:{FSPL_old.sum()}')\n",
    "        # print(f'FSPL_new:{FSPL.sum()}')\n",
    "        Hs = abs(CH * FSPL)\n",
    "\n",
    "    adj = adj_matrix(num_user * num_ap)\n",
    "\n",
    "    return Hs, position, adj, index\n",
    "\n",
    "\n",
    "def adj_matrix(num_nodes):\n",
    "    adj = []\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if not (i == j):\n",
    "                adj.append([i, j])\n",
    "    return np.array(adj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1781e1ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T13:45:54.363724Z",
     "start_time": "2023-07-03T13:45:54.333718500Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_network(position, radius, num_user, num_ap):\n",
    "    ap_pos, node_pos = np.split(position, [num_ap])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    circle = plt.Circle((0, 0), radius, fill=False, color='blue')\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.scatter(\n",
    "        [node[0] for node in ap_pos],\n",
    "        [node[1] for node in ap_pos],\n",
    "        color='blue'\n",
    "    )\n",
    "    ax.scatter(\n",
    "        [node[0] for node in node_pos],\n",
    "        [node[1] for node in node_pos],\n",
    "        color='red'\n",
    "    )\n",
    "    ax.add_patch(circle)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "993600de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T13:45:54.364725900Z",
     "start_time": "2023-07-03T13:45:54.351722300Z"
    }
   },
   "outputs": [],
   "source": [
    "def graph_build(channel_matrix, index_matrix):\n",
    "    num_user, num_ap = channel_matrix.shape\n",
    "    adjacency_matrix = adj_matrix(num_user * num_ap)\n",
    "\n",
    "    index_user = np.reshape(index_matrix[0], (-1, 1))\n",
    "    index_ap = np.reshape(index_matrix[1], (-1, 1))\n",
    "\n",
    "    x1 = np.reshape(channel_matrix, (-1, 1))\n",
    "    x2 = np.ones((num_user * num_ap, 1)) # power max here, for each?\n",
    "    x3 = np.zeros((num_user * num_ap, 1))\n",
    "    x = np.concatenate((x1, x2, x3),axis=1)\n",
    "\n",
    "    edge_index = adjacency_matrix\n",
    "    edge_attr = []\n",
    "\n",
    "    for each_interference in adjacency_matrix:\n",
    "        tx = each_interference[0]\n",
    "        rx = each_interference[1]\n",
    "\n",
    "        tmp = [channel_matrix[index_ap[rx][0]][index_user[tx][0]]]\n",
    "#         tmp = [\n",
    "#             [channel_matrix[index_ap[rx][0]][index_user[tx][0]]],\n",
    "#             [channel_matrix[index_ap[tx][0]][index_user[rx][0]]]\n",
    "#         ]\n",
    "        edge_attr.append(tmp)\n",
    "\n",
    "    # y = np.expand_dims(channel_matrix, axis=0)\n",
    "    # pos = np.expand_dims(weights_matrix, axis=0)\n",
    "\n",
    "    data = Data(x=torch.tensor(x, dtype=torch.float),\n",
    "                edge_index=torch.tensor(edge_index, dtype=torch.long).t().contiguous(),\n",
    "                edge_attr=torch.tensor(edge_attr, dtype=torch.float),\n",
    "                # y=torch.tensor(y, dtype=torch.float),\n",
    "                # pos=torch.tensor(pos, dtype=torch.float)\n",
    "                )\n",
    "    return data\n",
    "\n",
    "def build_all_data(channel_matrices, index_mtx):\n",
    "    num_sample = channel_matrices.shape[0]\n",
    "    data_list = []\n",
    "    for i in range(num_sample):\n",
    "        data = graph_build(channel_matrices[i], index_mtx)\n",
    "        data_list.append(data)\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c13b3e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T13:50:06.036647Z",
     "start_time": "2023-07-03T13:50:06.028645400Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_rate_calc(data, out, num_ap, num_user, train = True):\n",
    "    G = torch.reshape(out[:, 0], (-1, num_ap, num_user))\n",
    "    # print(f'Channel Coefficient: {G}')\n",
    "    # how to get channel from data and output\n",
    "    P = torch.reshape(out[:, 2], (-1, num_ap, num_user))\n",
    "    # print(f'Power: {P}')\n",
    "    desired_signal = torch.sum(torch.mul(P,G), axis=2).unsqueeze(-1)\n",
    "    # print(f'desired_signal: {desired_signal}')\n",
    "    P_UE = torch.sum(P, axis=1).unsqueeze(-1)\n",
    "    # print(f'P_UE: {P_UE}')\n",
    "    all_received_signal = torch.matmul(G, P_UE)\n",
    "    # print(f'all_received_signal: {all_received_signal}')\n",
    "    interference = all_received_signal - desired_signal\n",
    "    # print(f'interference: {interference}')\n",
    "    rate = torch.log(1 + torch.div(desired_signal, interference))\n",
    "    sum_rate = torch.mean(torch.sum(rate, 1))\n",
    "    if train:\n",
    "        power_max = torch.reshape(out[:, 1], (-1, num_ap, num_user))\n",
    "        regularization = torch.mean(P - power_max)\n",
    "        # return torch.neg(sum_rate - regularization)\n",
    "        return torch.neg(sum_rate)\n",
    "    else:\n",
    "        return sum_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f74ab996",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T13:50:39.000240700Z",
     "start_time": "2023-07-03T13:50:38.994239200Z"
    }
   },
   "outputs": [],
   "source": [
    "K = 10  # number of APs\n",
    "N = 20  # number of nodes\n",
    "R = 10  # radius\n",
    "\n",
    "num_train = 20  # number of training samples\n",
    "num_test = 4  # number of test samples\n",
    "\n",
    "reg = 1e-2\n",
    "pmax = 1\n",
    "var_db = 10\n",
    "var = 1 / 10 ** (var_db / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8777ec8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T13:50:39.936936300Z",
     "start_time": "2023-07-03T13:50:39.692880800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Data for training and testing\n",
    "X_train, pos_train, adj_train, index_train = generate_channels_wsn(K, N, num_train, var, R)\n",
    "X_test, pos_test, adj_test, index_test = generate_channels_wsn(K, N, num_test, var, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c0190ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T13:50:44.643749500Z",
     "start_time": "2023-07-03T13:50:40.596836100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preparing Data in to graph structured for model\n",
    "train_data_list = build_all_data(X_train, index_train)\n",
    "test_data_list = build_all_data(X_test, index_test)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GCNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.9)\n",
    "\n",
    "train_loader = DataLoader(train_data_list, batch_size=64, shuffle=False, num_workers=1)\n",
    "test_loader = DataLoader(test_data_list, batch_size=2000, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bde0db4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T13:50:44.645750Z",
     "start_time": "2023-07-03T13:50:44.643749500Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_rate_calc_old_version(data, out, num_ap, num_user, train = True):\n",
    "    G = torch.reshape(out[:, 0], (-1, num_ap, num_user))\n",
    "    # how to get channel from data and output\n",
    "    P = torch.reshape(out[:, 2], (-1, num_ap, num_user))\n",
    "    desired_signal = np.sum(torch.mul(P, G), axis=1)\n",
    "    P_UE = np.sum(P, axis=0)\n",
    "    all_received_signal = G @ P_UE\n",
    "    interference = all_received_signal - desired_signal\n",
    "    rate = torch.log(1 + torch.div(desired_signal, interference))\n",
    "    sum_rate = torch.mean(torch.sum(rate, 1))\n",
    "    if train:\n",
    "        return torch.neg(sum_rate)\n",
    "    else:\n",
    "        return sum_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae0cbbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T14:18:04.525342500Z",
     "start_time": "2023-07-03T13:50:48.564774700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training and Testing model\n",
    "training_loss = []\n",
    "testing_loss = []\n",
    "for epoch in range(1, 200):\n",
    "    total_loss = 0\n",
    "    for each_data in train_loader:\n",
    "        data = each_data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = data_rate_calc(data, out, K, N, train=True)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item() # * data.num_graphs\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = total_loss / num_train\n",
    "    training_loss.append(train_loss)\n",
    "\n",
    "    if (epoch % 1 == 0):\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        for each_data in test_loader:\n",
    "            data = each_data.to(device)\n",
    "            out = model(data)\n",
    "            loss = data_rate_calc(data, out, K, N, train=False)\n",
    "            total_loss += loss.item() # * data.num_graphs\n",
    "\n",
    "        test_loss = total_loss / num_test\n",
    "        testing_loss.append(test_loss)\n",
    "        if (epoch % 10 == 0):\n",
    "          print('Epoch {:03d}, Train Loss: {:.4f}, Val Loss: {:.4f}'.format(\n",
    "              epoch, train_loss, test_loss))\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a4fe0",
   "metadata": {},
   "source": [
    "## Plot the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48861da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating the first axis\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plotting the first data on the first axis\n",
    "ax1.plot(training_loss, 'b-', label='Training Loss')\n",
    "ax1.set_xlabel('Epoch(s)')\n",
    "ax1.set_ylabel('Training Loss', color='b')\n",
    "ax1.tick_params('y', colors='b')\n",
    "\n",
    "# Creating the second axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plotting the second data on the second axis\n",
    "ax2.plot(testing_loss, 'r-', label='Testing Data Rate')\n",
    "ax2.set_ylabel('Testing Data Rate', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "\n",
    "# Combining the legends\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "lines = lines_1 + lines_2\n",
    "labels = labels_1 + labels_2\n",
    "\n",
    "ax1.legend(lines, labels, loc='center left', bbox_to_anchor=(0, 0.5))\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
